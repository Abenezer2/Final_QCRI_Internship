{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR,draw_ocr\n",
    "import layoutparser as lp\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from transformers import TableTransformerForObjectDetection\n",
    "from transformers import DetrFeatureExtractor\n",
    "import torch\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "import csv\n",
    "import ast\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, GridSearchCV, ParameterGrid, StratifiedKFold, RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "import os\n",
    "import re\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import tabula.io as tabula\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image as PilImage\n",
    "from img2table.document import Image as TableImage\n",
    "from tabula.io import read_pdf\n",
    "import joblib\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_detection_microsoft(image, threshold=0.3):\n",
    "    model_microsoft = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-transformer-detection\")\n",
    "    feature_extractor = DetrFeatureExtractor()\n",
    "    width, height = image.size\n",
    "    target_sizes = [(height, width)]\n",
    "    encoding = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model_microsoft(**encoding)\n",
    "    results = feature_extractor.post_process_object_detection(outputs, threshold=threshold, target_sizes=target_sizes)[0]\n",
    "    return {\n",
    "        'microsoft_probabilities': str(results['scores'].tolist())\n",
    "    }\n",
    "\n",
    "def table_detection_paddle(image):\n",
    "    model = lp.PaddleDetectionLayoutModel(\n",
    "        config_path=\"lp://TableBank/ppyolov2_r50vd_dcn_365e_tableBank_latex/config\",\n",
    "        label_map={0: \"Table\"},\n",
    "        threshold=0.3,\n",
    "        enforce_cpu=False,\n",
    "        enable_mkldnn=True\n",
    "    )\n",
    "    image_cv = np.array(image)[:, :, ::-1]  # Convert PIL.Image to cv2 image (BGR)\n",
    "    layout = model.detect(image_cv)\n",
    "    scores = [l.score for l in layout if l.type == 'Table']\n",
    "    return {\n",
    "        'paddle_probabilities': str(scores)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_table_pdfplumber(img_pdf_path):\n",
    "    try:\n",
    "        with pdfplumber.open(img_pdf_path) as pdf:\n",
    "            page = pdf.pages[0]\n",
    "            table = page.extract_table()\n",
    "            return bool(table)\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def detect_table_tabula(img_pdf_path):\n",
    "    try:\n",
    "        tables = tabula.read_pdf(img_pdf_path, pages=1)\n",
    "        return len(tables) > 0\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def detect_table_img2table(img_path):\n",
    "    try:\n",
    "        ti = TableImage(img_path)\n",
    "        table_data = ti.get_table()\n",
    "        return bool(table_data)\n",
    "    except Exception as e:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_table_detector(pdf_directory, output_file, table_directory, no_table_directory):\n",
    "    data = []\n",
    "\n",
    "    # Iterate over the PDF files in the directory\n",
    "    for file in os.listdir(pdf_directory):\n",
    "        if not file.endswith(\".pdf\"):  # Skip non-PDF files\n",
    "            continue\n",
    "        file_path = os.path.join(pdf_directory, file)\n",
    "        # Convert PDF to images\n",
    "        images = convert_from_path(file_path)\n",
    "        for i, img in enumerate(images, start=1):\n",
    "            pdf_name = os.path.splitext(file)[0]\n",
    "            page_number = i\n",
    "\n",
    "            # Temporary image file path for pdfplumber and tabula\n",
    "            temp_img_pdf_path = f'temp_{pdf_name}_page_{page_number}.pdf'\n",
    "            img.save(temp_img_pdf_path, 'PDF')\n",
    "\n",
    "            # Detect tables using pdfplumber\n",
    "            table_pdfplumber = detect_table_pdfplumber(temp_img_pdf_path)\n",
    "\n",
    "            # Detect tables using tabula\n",
    "            table_tabula = detect_table_tabula(temp_img_pdf_path)\n",
    "\n",
    "            # Detect tables using img2table\n",
    "            table_img2table = detect_table_img2table(f'temp_{pdf_name}_page_{page_number}.png')\n",
    "\n",
    "            # Cleanup temporary files\n",
    "            os.remove(temp_img_pdf_path)\n",
    "\n",
    "            # Detect tables using Microsoft model\n",
    "            ms_result = table_detection_microsoft(img)\n",
    "            ms_probabilities = ast.literal_eval(ms_result['microsoft_probabilities'])\n",
    "            ms_max_prob = max(ms_probabilities) if ms_probabilities else 0\n",
    "            \n",
    "            # Detect tables using Paddle model\n",
    "            paddle_result = table_detection_paddle(img)\n",
    "            paddle_probabilities = ast.literal_eval(paddle_result['paddle_probabilities'])\n",
    "            paddle_max_prob = max(paddle_probabilities) if paddle_probabilities else 0\n",
    "\n",
    "            # Append the results\n",
    "            data.append({\n",
    "                'pdf_name': pdf_name,\n",
    "                'page_number': page_number,\n",
    "                'microsoft_max_probabilities': ms_max_prob,\n",
    "                'paddle_max_probabilities': paddle_max_prob,\n",
    "                'pdfplumber_table_found': table_pdfplumber,\n",
    "                'img2table_table_found': table_tabula,\n",
    "                'tabula_table_found': table_img2table\n",
    "            })\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    tables = pd.DataFrame(data)\n",
    "\n",
    "    X_test= tables[[\"microsoft_max_probabilities\", \"paddle_max_probabilities\",\"pdfplumber_table_found\", \"img2table_table_found\", \"tabula_table_found\" ]]\n",
    "    \n",
    "    model_CatBoost_loaded_model = CatBoostClassifier().load_model(\"./model_CatBoost.cbm final_trained_model.cbm\")\n",
    "\n",
    "    # Load the model from the file\n",
    "\n",
    "    # Use the loaded model to make predictions\n",
    "    prediction = model_CatBoost_loaded_model.predict(X_test)\n",
    "\n",
    "    tables[\"table_found\"] = prediction\n",
    "    \n",
    "    \n",
    "    # Save the images to corresponding folders\n",
    "    for i, row in tables.iterrows():\n",
    "        img = images[i]\n",
    "        if row['table_found'] == \"True\":\n",
    "            img.save(os.path.join(table_directory, f'{row[\"pdf_name\"]}_page_{row[\"page_number\"]}.png'))\n",
    "        else:\n",
    "            img.save(os.path.join(no_table_directory, f'{row[\"pdf_name\"]}_page_{row[\"page_number\"]}.png'))\n",
    "\n",
    "    # Remove unnecessary columns\n",
    "    tables = tables.drop(columns = [\"microsoft_max_probabilities\", \"paddle_max_probabilities\", \"pdfplumber_table_found\", \"img2table_table_found\", \"tabula_table_found\"])\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    tables.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0802 16:23:26.917349 229287424 analysis_config.cc:121] Please use PaddlePaddle with GPU version.\n",
      "E0802 16:23:34.069947 229287424 analysis_config.cc:121] Please use PaddlePaddle with GPU version.\n",
      "E0802 16:23:40.642962 229287424 analysis_config.cc:121] Please use PaddlePaddle with GPU version.\n",
      "E0802 16:23:47.181788 229287424 analysis_config.cc:121] Please use PaddlePaddle with GPU version.\n",
      "E0802 16:23:53.730849 229287424 analysis_config.cc:121] Please use PaddlePaddle with GPU version.\n",
      "E0802 16:24:00.213634 229287424 analysis_config.cc:121] Please use PaddlePaddle with GPU version.\n",
      "E0802 16:24:06.722815 229287424 analysis_config.cc:121] Please use PaddlePaddle with GPU version.\n",
      "E0802 16:24:13.345325 229287424 analysis_config.cc:121] Please use PaddlePaddle with GPU version.\n"
     ]
    }
   ],
   "source": [
    "final_table_detector(\"./Test_data\", \"./Test_data/output.csv\", \"./Test_data/Table\",\"./Test_data/No_Table\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
