{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR,draw_ocr\n",
    "import layoutparser as lp\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from transformers import TableTransformerForObjectDetection\n",
    "from transformers import DetrFeatureExtractor\n",
    "import torch\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "import csv\n",
    "import ast\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, GridSearchCV, ParameterGrid, StratifiedKFold, RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "import joblib\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_detection_microsoft(image, threshold=0.3):\n",
    "    model_microsoft = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-transformer-detection\")\n",
    "    feature_extractor = DetrFeatureExtractor()\n",
    "    width, height = image.size\n",
    "    target_sizes = [(height, width)]\n",
    "    encoding = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model_microsoft(**encoding)\n",
    "    results = feature_extractor.post_process_object_detection(outputs, threshold=threshold, target_sizes=target_sizes)[0]\n",
    "    return {\n",
    "        'microsoft_probabilities': str(results['scores'].tolist())\n",
    "    }\n",
    "\n",
    "def table_detection_paddle(image):\n",
    "    model = lp.PaddleDetectionLayoutModel(\n",
    "        config_path=\"lp://TableBank/ppyolov2_r50vd_dcn_365e_tableBank_latex/config\",\n",
    "        label_map={0: \"Table\"},\n",
    "        threshold=0.3,\n",
    "        enforce_cpu=False,\n",
    "        enable_mkldnn=True\n",
    "    )\n",
    "    image_cv = np.array(image)[:, :, ::-1]  # Convert PIL.Image to cv2 image (BGR)\n",
    "    layout = model.detect(image_cv)\n",
    "    scores = [l.score for l in layout if l.type == 'Table']\n",
    "    return {\n",
    "        'paddle_probabilities': str(scores)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_table_detector(pdf_directory, output_file, table_directory, no_table_directory):\n",
    "    data = []\n",
    "\n",
    "    # Iterate over the PDF files in the directory\n",
    "    for file in os.listdir(pdf_directory):\n",
    "        if not file.endswith(\".pdf\"):  # Skip non-PDF files\n",
    "            continue\n",
    "        file_path = os.path.join(pdf_directory, file)\n",
    "        # Convert PDF to images\n",
    "        images = convert_from_path(file_path)\n",
    "        for i, img in enumerate(images, start=1):\n",
    "            pdf_name = os.path.splitext(file)[0]\n",
    "            page_number = i\n",
    "            # Detect tables using Microsoft model\n",
    "            ms_result = table_detection_microsoft(img)\n",
    "            ms_probabilities = ast.literal_eval(ms_result['microsoft_probabilities'])\n",
    "            ms_max_prob = max(ms_probabilities) if ms_probabilities else 0\n",
    "            # Detect tables using Paddle model\n",
    "            paddle_result = table_detection_paddle(img)\n",
    "            paddle_probabilities = ast.literal_eval(paddle_result['paddle_probabilities'])\n",
    "            paddle_max_prob = max(paddle_probabilities) if paddle_probabilities else 0\n",
    "            # Append the results\n",
    "            data.append({\n",
    "                'pdf_name': pdf_name,\n",
    "                'page_number': page_number,\n",
    "                'microsoft_max_probabilities': ms_max_prob,\n",
    "                'paddle_max_probabilities': paddle_max_prob\n",
    "            })\n",
    "\n",
    "    # Create a DataFrame\n",
    "    tables = pd.DataFrame(data)\n",
    "\n",
    "    X_test= tables[[\"microsoft_max_probabilities\", \"paddle_max_probabilities\"]]\n",
    "    \n",
    "    # Load the model from the file\n",
    "    model_CatBoost_from_joblib = joblib.load('./model_CatBoost.pkl')\n",
    "\n",
    "    # Use the loaded model to make predictions\n",
    "    prediction = model_CatBoost_from_joblib.predict(X_test)\n",
    "\n",
    "    tables[\"table_found\"] = prediction\n",
    "    \n",
    "    # Conditions to check\n",
    "    condition = (tables['table_found'] == \"False\") & ((tables['paddle_max_probabilities'] > 0.9) | (tables['microsoft_max_probabilities'] > 0.9))\n",
    "    # Update 'Cat_boost' field where condition is True\n",
    "    tables.loc[condition, 'table_found'] = \"True\"\n",
    "    \n",
    "    # Save the images to corresponding folders\n",
    "    for i, row in tables.iterrows():\n",
    "        img = images[i]\n",
    "        if row['table_found'] == \"True\":\n",
    "            img.save(os.path.join(table_directory, f'{row[\"pdf_name\"]}_page_{row[\"page_number\"]}.png'))\n",
    "        else:\n",
    "            img.save(os.path.join(no_table_directory, f'{row[\"pdf_name\"]}_page_{row[\"page_number\"]}.png'))\n",
    "\n",
    "    # Remove unnecessary columns\n",
    "    tables = tables.drop(columns = [\"microsoft_max_probabilities\", \"paddle_max_probabilities\"])\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    tables.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0802 16:23:26.917349 229287424 analysis_config.cc:121] Please use PaddlePaddle with GPU version.\n",
      "E0802 16:23:34.069947 229287424 analysis_config.cc:121] Please use PaddlePaddle with GPU version.\n",
      "E0802 16:23:40.642962 229287424 analysis_config.cc:121] Please use PaddlePaddle with GPU version.\n",
      "E0802 16:23:47.181788 229287424 analysis_config.cc:121] Please use PaddlePaddle with GPU version.\n",
      "E0802 16:23:53.730849 229287424 analysis_config.cc:121] Please use PaddlePaddle with GPU version.\n",
      "E0802 16:24:00.213634 229287424 analysis_config.cc:121] Please use PaddlePaddle with GPU version.\n",
      "E0802 16:24:06.722815 229287424 analysis_config.cc:121] Please use PaddlePaddle with GPU version.\n",
      "E0802 16:24:13.345325 229287424 analysis_config.cc:121] Please use PaddlePaddle with GPU version.\n"
     ]
    }
   ],
   "source": [
    "final_table_detector(\"./Test_data\", \"./Test_data/output.csv\", \"./Test_data/Table\",\"./Test_data/No_Table\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
